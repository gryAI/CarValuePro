***
## Introduction <br>

The CarValuePro project focuses on predicting the market value of pre-owned vehicles in the Philippines. It aims to offer sellers a suggested price for their vehicles and provide buyers with a benchmark to help them compare the prices of vehicles they are considering. <br> <br>

![image](https://github.com/user-attachments/assets/31ee6e2b-d70c-4e87-90cd-0da0804a045e)


To accomplish this, the following project components are involved:
- Data Pipeline Development and Deployment
  - Extraction (Web Scraping)
  - Transformation
  - Loading (Initial Full Load and Daily Incremental Load)
- Model Development
- Web App Development
- Model Deployment
- Model Monitoring

***

## Project Details

To replicate this project, you can follow the steps outlined below. <br> For a more detailed documentation, please check this Project's Wiki Page _(still in development)_.

### Environment Setup
1. Clone this repository
```
git clone https://github.com/gryAI/CarValuePro
```
   
2. Create a virtual environment <br>
```
pip install pyenv
pip install virtualenv
```
3. Add `PYTHONPATH` in the `venv/Scripts/activate` file
```
echo 'export PYTHONPATH="/path/to/your/src"' >> path/to/your/venv/Scripts/activate
```
4. Activate the virtual environment <br>
```
source venv/Scripts/activate
```
5. Install dependencies
```
pip install -r requirements.txt
```

### Local Module Execution
You can choose to run the project locally by following these steps. This approach is suitable if you only intend to extract data from the website once and are not concerned with subsequent postings.
- Run orchestrators from `scripts`
```
python scripts/run_full_pipeline.py
```

- Notes on how to run specific modules from `src`
```
# Run from project root directory
python -m src.data_pipeline.full_pipeline.extract

# Run from src directory
cd src
python -m data_pipeline.full_pipeline.extract
```


### Dockerization and Deployment
If you wish to extract subsequent postings on a daily basis, I recommend following these steps to deploy the pipeline, ensuring that the scheduled tasks run continuously.
- Dockerize the pipeline <br>
- Deploy the pipeline as a Background Worker in Render

***

## Project Structure

```plaintext
CarValueProRepo/
â”‚
â”œâ”€â”€ ðŸ“‚ src/                                                            # Main source code for the web app, model, and data pipeline
â”‚   â”œâ”€â”€ ðŸ“‚ app/                                                        # Web application code
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ routes.py
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ views.py
â”‚   â”‚   â”œâ”€â”€ ðŸ“‚ static/                                                 # Static files (e.g., CSS, JS)
â”‚   â”‚   â”œâ”€â”€ ðŸ“‚ templates/                                              # HTML templates
â”‚   â”‚   â””â”€â”€ ðŸ“„ config.py                                               # Configuration settings
â”‚   â”œâ”€â”€ ðŸ“‚ model/                                                      # Machine learning model code
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ train.py
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ evaluate.py
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ predict.py
â”‚   â”‚   â””â”€â”€ ðŸ“„ utils.py
â”‚   â”œâ”€â”€ ðŸ“‚ data_pipeline/                                               # Data processing and pipeline code
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ extract.py
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ transform.py
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ load.py
â”‚   â”‚   â”œâ”€â”€ ðŸ“‚ airflow/                                                 # Airflow DAGs and configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“‚ dags/                                                # DAG definitions
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“„ example_dag.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ data_pipeline_dag.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“‚ plugins/                                             # Custom Airflow plugins
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ custom_plugin.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ðŸ“‚ config/                                              # Airflow configuration files
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ airflow.cfg
â”‚   â”‚   â”‚   â””â”€â”€ ðŸ“„ Dockerfile                                           # Dockerfile for Airflow setup (if applicable)
â”‚
â”œâ”€â”€ ðŸ“‚ deployment/                                                      # Deployment-related files and configurations
â”‚   â”œâ”€â”€ ðŸ“‚ docker/                                                      # Docker-related files
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ Dockerfile                                               # Dockerfile for the web app or other services
â”‚   â”‚   â””â”€â”€ ðŸ“„ docker-compose.yml                                       # Docker Compose file for local development
â”‚   â”œâ”€â”€ ðŸ“‚ k8s/                                                         # Kubernetes configurations (if applicable)
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ deployment.yaml                                          # Kubernetes deployment configuration
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ service.yaml                                             # Kubernetes service configuration
â”‚   â”‚   â””â”€â”€ ðŸ“„ ingress.yaml                                             # Kubernetes ingress configuration (if applicable)
â”‚   â”œâ”€â”€ ðŸ“‚ scripts/                                                     # Deployment scripts (e.g., shell scripts)
â”‚   â”‚   â””â”€â”€ ðŸ“„ deploy.sh
â”‚   â””â”€â”€ ðŸ“‚ configs/                                                     # Environment-specific configuration files
â”‚       â””â”€â”€ ðŸ“„ production.env  
â”‚
â”œâ”€â”€ ðŸ“‚ tests/                                                           # Test scripts
â”‚   â”œâ”€â”€ ðŸ“„ __init__.py
â”‚   â”œâ”€â”€ ðŸ“„ test_app.py
â”‚   â”œâ”€â”€ ðŸ“„ test_model.py
â”‚   â”œâ”€â”€ ðŸ“„ test_pipeline.py
â”‚   â””â”€â”€ ðŸ“„ test_airflow.py                                              # Tests for Airflow DAGs
â”‚
â”œâ”€â”€ ðŸ“‚ data/                                                            # Data files or databases
â”‚   â”œâ”€â”€ ðŸ“‚ raw/                                                         # Raw data files
â”‚   â”œâ”€â”€ ðŸ“‚ processed/                                                   # Processed data files
â”‚   â””â”€â”€ ðŸ“‚ models/                                                      # Saved model files
â”‚
â”œâ”€â”€ ðŸ“‚ reports/                                                         # Reports and visualizations
â”‚   â”œâ”€â”€ ðŸ“‚ visualizations/                                              # Data visualizations and charts
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ dashboard.png
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ performance_metrics.png
â”‚   â”‚   â””â”€â”€ ðŸ“„ trends_analysis.png
â”‚   â”œâ”€â”€ ðŸ“‚ notebooks/                                                   # Jupyter notebooks with analysis
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ data_exploration.ipynb
â”‚   â”‚   â”œâ”€â”€ ðŸ“„ model_evaluation.ipynb
â”‚   â”‚   â””â”€â”€ ðŸ“„ final_report.ipynb
â”‚   â””â”€â”€ ðŸ“‚ summaries/                                                   # Summary reports and insights
â”‚       â”œâ”€â”€ ðŸ“„ executive_summary.md
â”‚       â”œâ”€â”€ ðŸ“„ weekly_update.md
â”‚       â””â”€â”€ ðŸ“„ project_review.md
â”‚
â”œâ”€â”€ ðŸ“‚ docs/                                                            # Documentation
â”‚   â”œâ”€â”€ ðŸ“„ model_description.md
â”‚   â”œâ”€â”€ ðŸ“„ api_documentation.md  
â”‚   â”œâ”€â”€ ðŸ“„ airflow_setup.md
â”‚   â”œâ”€â”€ ðŸ“„ architecture_diagram.png                                     # Documentation for setting up and using Airflow
â”‚   â””â”€â”€ ðŸ“„ architecture_diagram.jpg
â”‚
â”œâ”€â”€ ðŸ“„ requirements.txt                                                 # Python dependencies
â”œâ”€â”€ ðŸ“„ README.md                                                        # Project overview
â””â”€â”€ ðŸ“„ .gitignore                                                       # Git ignore file

